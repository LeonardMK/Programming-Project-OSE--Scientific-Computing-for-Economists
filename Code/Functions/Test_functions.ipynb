{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters set for Benchmarking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook I set up parameters used for tuning optimization algorithms. Since every algorithm accepts different parameters they are defined manually. I generate sets of parameters from a uniform distribution over the applicable range. To make sure that all combinations are poosible I use the package `itertools`. If the parameter range i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load some libraries first\n",
    "import itertools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pygmo as pg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Target values\n",
    "\n",
    "Every test function implemented in the `pygmo` library is fixed cost. Therefore a solution vector and value are known. To assess the quality of a solution I need to get these values. Since `pygmo` provides no easily accesible interface to a solution once the problem is defined I define my own function called `get_target`, which provides us with the solution vector and the function value of a given problem. Additional parameters can be set using a dicitonary for `kwargs`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_target(problem_name, kwargs_problem = None):\n",
    "    \n",
    "    if kwargs_problem is not None:\n",
    "        try:\n",
    "            target = [getattr(pg, problem_name)(**kwargs_problem).best_known()]\n",
    "            f_best = pg.problem(getattr(pg, problem_name)(**kwargs_problem)).fitness(target[0])\n",
    "        except AttributeError:\n",
    "            target = [eval(problem_name)(**kwargs_problem).best_known()]\n",
    "            if target[0].ndim == 1:\n",
    "                f_best = pg.problem(eval(problem_name)(**kwargs_problem)).fitness(target[0])\n",
    "            else:\n",
    "                f_best = pg.problem(eval(problem_name)(**kwargs_problem)).fitness(target[0][0])\n",
    "    else:\n",
    "        try:\n",
    "            target = [getattr(pg, problem_name)().best_known()]\n",
    "            f_best = pg.problem(getattr(pg, problem_name)()).fitness(target[0])\n",
    "        except AttributeError:\n",
    "            target = [eval(problem_name)().best_known()]\n",
    "            if target[0].ndim == 1:\n",
    "                f_best = pg.problem(eval(problem_name)()).fitness(target[0])\n",
    "            else:\n",
    "                f_best = pg.problem(eval(problem_name)()).fitness(target[0][0])            \n",
    "        \n",
    "    target.append(f_best)\n",
    "    \n",
    "    return target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([1., 1.]), array([0.])]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_target(\"rosenbrock\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aggregate Functions\n",
    "Pandas aggregate method is not able to take additional arguments. Define a 25% and 75% quantile function for this task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def q25(x):\n",
    "    return x.quantile(0.25)\n",
    "\n",
    "def q75(x):\n",
    "    return x.quantile(0.75)\n",
    "\n",
    "def iqr(x):\n",
    "    return x.quantile(0.75) - x.quantile(0.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### User Defined Benchmarking Functions\n",
    "The pygmo library is missing out on some of the most well known problems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class beale:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.dim = 2\n",
    "        \n",
    "    def fitness(self, x):\n",
    "        return [\n",
    "            (1.5 - x[0] + x[0] * x[1]) ** 2 + \n",
    "            (2.25 -x[0] + x[0] * x[1] ** 2) ** 2 +\n",
    "            (2.625 - x[0] + x[0] * x[1] ** 3) ** 2\n",
    "        ]\n",
    "    \n",
    "    def get_bounds(self):\n",
    "        return ([-4.5] * 2, [4.5] * 2)\n",
    "    \n",
    "    def get_name(self):\n",
    "        return \"Beale Function\"\n",
    "    \n",
    "    def best_known(self):\n",
    "        return np.array([3, 0.5])\n",
    "    \n",
    "    def gradient(self, x) :\n",
    "        return pg.estimate_gradient(lambda x: self.fitness(x), x)\n",
    "    \n",
    "class goldstein_price:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.dim = 2\n",
    "        \n",
    "    def fitness(self, x):\n",
    "        return [\n",
    "            ((1 + (x[0] + x[1] + 1) ** 2) * \n",
    "            (19 - 14 * x[0] + 3 * x[0] ** 2 - 14 * x[1] + 6 * np.prod(x) + 3 * x[1] ** 2)) *\n",
    "            (30 + (2 * x[0] - 3 * x[1]) ** 2 * (18 - 32 * x[0] + 12 * x[0] ** 2 + 48 * x[1] - 36 * np.prod(x) + 27 * x[1] ** 2))\n",
    "        ]\n",
    "    \n",
    "    def get_bounds(self):\n",
    "        return ([-2] * 2, [2] * 2)\n",
    "    \n",
    "    def get_name(self):\n",
    "        return \"Goldstein-Price Function\"\n",
    "    \n",
    "    def best_known(self):\n",
    "        return np.array([0, -1])\n",
    "    \n",
    "    def gradient(self, x):\n",
    "        return pg.estimate_gradient(lambda x: self.fitness(x), x)\n",
    "    \n",
    "class booth:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.dim = 2\n",
    "        \n",
    "    def fitness(self, x):\n",
    "        return [\n",
    "            (x[0] + 2 * x[1] - 7) ** 2 + (2 * x[0] + x[1] - 5) ** 2\n",
    "        ]\n",
    "    \n",
    "    def get_bounds(self):\n",
    "        return ([-10] * 2, [10] * 2)\n",
    "    \n",
    "    def get_name(self):\n",
    "        return \"Booth Function\"\n",
    "    \n",
    "    def best_known(self):\n",
    "        return np.array([1, 3])\n",
    "    \n",
    "    def gradient(self, x):\n",
    "        return pg.estimate_gradient(lambda x: self.fitness(x), x)\n",
    "\n",
    "class bukin_n6:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.dim = 2\n",
    "        \n",
    "    def fitness(self, x):\n",
    "        return [\n",
    "            100 * np.sqrt(np.abs(x[1] - 0.01 * x[0] ** 2)) + 0.01 * np.abs(x[0] + 10)\n",
    "        ]\n",
    "        \n",
    "    def get_bounds(self):\n",
    "        return ([-15, -3], [-5, 3])\n",
    "    \n",
    "    def get_name(self):\n",
    "        return \"Bukin Function N.6\"\n",
    "    \n",
    "    def best_known(self):\n",
    "        return np.array([-10, 1])\n",
    "    \n",
    "    def gradient(self, x):\n",
    "        return pg.estimate_gradient(lambda x: self.fitness(x), x)\n",
    "\n",
    "class matyas:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.dim = 2\n",
    "        \n",
    "    def fitness(self, x):\n",
    "        return [\n",
    "            0.26 * (x[0] ** 2 + x[1] ** 2) - 0.48 * np.prod(x)\n",
    "        ]\n",
    "    \n",
    "    def get_bounds(self):\n",
    "        return ([-10] * 2, [10] * 2)\n",
    "    \n",
    "    def get_name(self):\n",
    "        return \"Matyas Function\"\n",
    "    \n",
    "    def best_known(self):\n",
    "        return np.array([0, 0])\n",
    "    \n",
    "    def gradient(self, x):\n",
    "        return pg.estimate_gradient(lambda x: self.fitness(x), x)\n",
    "\n",
    "class levi_n13:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.dim = 2\n",
    "        \n",
    "    def fitness(self, x):\n",
    "        return [\n",
    "            (\n",
    "                np.sin(3 * np.pi * x[0]) ** 2 + \n",
    "                (x[0] - 1) ** 2 * (1 + np.sin(3 * np.pi * x[1]) ** 2) + \n",
    "                (x[1] - 1) ** 2 * (1 + np.sin(2 * np.pi * x [1]) ** 2)\n",
    "            )\n",
    "        ]\n",
    "    \n",
    "    def get_bounds(self):\n",
    "        return ([-10] * 2, [10] * 2)\n",
    "    \n",
    "    def get_name(self):\n",
    "        return \"Lévi Function N.13\"\n",
    "    \n",
    "    def best_known(self):\n",
    "        return np.array([1, 1])\n",
    "    \n",
    "    def gradient(self, x):\n",
    "        return pg.estimate_gradient(lambda x: self.fitness(x), x)\n",
    "    \n",
    "class himmelblau:\n",
    "\n",
    "    def __init__(self):\n",
    "        self.dim = 2\n",
    "        \n",
    "    def fitness(self, x):\n",
    "        return [\n",
    "            (x[0] ** 2 + x[1] - 11) ** 2 + (x[0] + x[1] ** 2 - 7) ** 2\n",
    "        ]\n",
    "    \n",
    "    def get_bounds(self):\n",
    "        return ([-5] * 2, [5] * 2)\n",
    "    \n",
    "    def get_name(self):\n",
    "        return \"Himmelblau's Function\"\n",
    "    \n",
    "    def best_known(self):\n",
    "        return np.array([\n",
    "            [3, 2],\n",
    "            [-2.805118, 3.131312],\n",
    "            [-3.779310, -3.283186],\n",
    "            [3.584428, -1.848126]\n",
    "        ])\n",
    "    \n",
    "    def gradient(self, x):\n",
    "        return pg.estimate_gradient(lambda x: self.fitness(x), x)\n",
    "    \n",
    "class camel:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.dim = 2\n",
    "        \n",
    "    def fitness(self, x):\n",
    "        return [\n",
    "            2 * x[0] ** 2 - 1.05 * x[0] ** 4 + x[0] ** 6 / 6 + np.prod(x) + x[1] ** 2\n",
    "        ]\n",
    "    \n",
    "    def get_bounds(self):\n",
    "        return ([-5] * 2, [5] * 2)\n",
    "    \n",
    "    def get_name(self):\n",
    "        return \"Three Hump Camel Function\"\n",
    "    \n",
    "    def best_known(self):\n",
    "        return np.array([0, 0])\n",
    "    \n",
    "    def gradient(self, x):\n",
    "        return pg.estimate_gradient(lambda x: self.fitness(x), x)\n",
    "    \n",
    "class easom:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.dim = 2\n",
    "        \n",
    "    def fitness(self, x):\n",
    "        return [\n",
    "            (\n",
    "                -np.cos(x[0]) * \n",
    "                np.cos(x[1]) * \n",
    "                np.exp(-((x[0] - np.pi) ** 2 + (x[1] - np.pi) ** 2))\n",
    "            )\n",
    "        ]\n",
    "    \n",
    "    def get_bounds(self):\n",
    "        return ([-100] * 2, [100] * 2)\n",
    "    \n",
    "    def get_name(self):\n",
    "        return \"Easom Function\"\n",
    "    \n",
    "    def best_known(self):\n",
    "        return np.array([np.pi, np.pi])\n",
    "    \n",
    "    def gradient(self, x):\n",
    "        return pg.estimate_gradient(lambda x: self.fitness(x), x)\n",
    "    \n",
    "class cross_in_tray:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.dim = 2\n",
    "        \n",
    "    def fitness(self, x):\n",
    "        return [\n",
    "            -0.0001 * (np.abs(\n",
    "                np.sin(x[0]) *\n",
    "                np.sin(x[1]) * \n",
    "                np.exp(\n",
    "                    np.abs(100 - np.sqrt(x[0] ** 2 + x[1] ** 2) / np.pi) +\n",
    "                    1\n",
    "                )\n",
    "            ) ** 0.1)\n",
    "        ]\n",
    "    \n",
    "    def get_bounds(self):\n",
    "        return ([-10] * 2, [10] * 2)\n",
    "    \n",
    "    def get_name(self):\n",
    "        return \"Cross-in-Tray Function\"\n",
    "    \n",
    "    def best_known(self):\n",
    "        return np.array([\n",
    "            [1.34941, -1.34941],\n",
    "            [1.34941, 1.34941],\n",
    "            [-1.34941, 1.34941],\n",
    "            [-1.34941, -1.34941]\n",
    "        ])\n",
    "    \n",
    "    def gradient(self, x):\n",
    "        return pg.estimate_gradient(lambda x: self.fitness(x), x)\n",
    "    \n",
    "class eggholder:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.dim = 2\n",
    "        \n",
    "    def fitness(self, x):\n",
    "        return [\n",
    "            -(x[1] + 47) *\n",
    "            np.sin(\n",
    "                np.sqrt(\n",
    "                    np.abs(\n",
    "                        x[0] / 2 + (x[1] + 47)\n",
    "                    )\n",
    "                )\n",
    "            ) - \n",
    "            x[0] * np.sin(\n",
    "                np.sqrt(\n",
    "                    np.abs(\n",
    "                        x[0] - (x[1] + 47)\n",
    "                    )\n",
    "                )\n",
    "            )\n",
    "        ]\n",
    "    \n",
    "    def get_bounds(self):\n",
    "        return ([-512] * 2, [512] * 2)\n",
    "    \n",
    "    def get_name(self):\n",
    "        return \"Eggholder Function\"\n",
    "    \n",
    "    def best_known(self):\n",
    "        return np.array([512, 404.2319])\n",
    "    \n",
    "    def gradient(self, x):\n",
    "        return pg.estimate_gradient(lambda x: self.fitness(x), x)\n",
    "    \n",
    "class h_table:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.dim = 2\n",
    "        \n",
    "    def fitness(self, x):\n",
    "        return [\n",
    "            - np.abs(\n",
    "                np.sin(x[0]) *\n",
    "                np.cos(x[1]) *\n",
    "                np.exp(\n",
    "                    np.abs(\n",
    "                        1 - np.sqrt(x[0] ** 2 + x[1] ** 2) / np.pi\n",
    "                    )\n",
    "                )\n",
    "            )\n",
    "        ]\n",
    "    \n",
    "    def get_bounds(self):\n",
    "        return ([-10] * 2, [10] * 2)\n",
    "    \n",
    "    def get_name(self):\n",
    "        return \"Hölder Table Function\"\n",
    "    \n",
    "    def best_known(self):\n",
    "        return np.array([\n",
    "            [8.05502, 9.66459],\n",
    "            [-8.05502, 9.66459],\n",
    "            [8.05502, -9.66459],\n",
    "            [-8.05502, -9.66459]\n",
    "        ])\n",
    "    \n",
    "    def gradient(self, x):\n",
    "        return pg.estimate_gradient(lambda x: self.fitness(x), x)\n",
    "    \n",
    "class mccormick:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.dim = 2\n",
    "        \n",
    "    def fitness(self, x):\n",
    "        return [\n",
    "            np.sin(np.sum(x)) +\n",
    "            (x[0] - x[1]) ** 2 + \n",
    "            1.5 * x[0] + 2.5 * x[1] + 1\n",
    "        ]\n",
    "    \n",
    "    def get_bounds(self):\n",
    "        return ([-1.5, -3], [4] * 2)\n",
    "    \n",
    "    def get_name(self):\n",
    "        return \"McCormick Function\"\n",
    "    \n",
    "    def best_known(self):\n",
    "        return np.array([-0.54719, -1.54719])\n",
    "    \n",
    "    def gradient(self, x):\n",
    "        return pg.estimate_gradient(lambda x: self.fitness(x), x)\n",
    "    \n",
    "class schaffer_n2:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.dim = 2\n",
    "        \n",
    "    def fitness(self, x):\n",
    "        return [\n",
    "            0.5 + (np.sin(x[0] ** 2 - x[1] ** 2) ** 2 - 0.5) /\n",
    "            (1 + 0.001 * (x[0] ** 2 + x[1] ** 2)) ** 2\n",
    "        ]\n",
    "    \n",
    "    def get_bounds(self):\n",
    "        return ([-100] * 2, [100] * 2)\n",
    "    \n",
    "    def get_name(self):\n",
    "        return \"Schaffer Function N.2\"\n",
    "    \n",
    "    def best_known(self):\n",
    "        return np.array([0, 0])\n",
    "    \n",
    "    def gradient(self, x):\n",
    "        return pg.estimate_gradient(lambda x: self.fitness(x), x)\n",
    "    \n",
    "class schaffer_n4:\n",
    "\n",
    "    def __init__(self):\n",
    "        self.dim = 2\n",
    "        \n",
    "    def fitness(self, x):\n",
    "        return [\n",
    "            0.5 + \n",
    "            (np.cos(\n",
    "                np.sin(\n",
    "                    np.abs(\n",
    "                        x[0] ** 2 - x[1] ** 2\n",
    "                    )\n",
    "                )\n",
    "            ) ** 2 - 0.5) / \n",
    "            (1 + 0.001 * (x[0] ** 2 + x[1] ** 2)) ** 2\n",
    "        ]\n",
    "    \n",
    "    def get_bounds(self):\n",
    "        return ([-100] * 2, [100] * 2)\n",
    "    \n",
    "    def get_name(self):\n",
    "        return \"Schaffer Function N.4\"\n",
    "    \n",
    "    def best_known(self):\n",
    "        return np.array([\n",
    "            [0, 1.25313],\n",
    "            [0, -1.25313]\n",
    "        ])\n",
    "    \n",
    "    def gradient(self, x):\n",
    "        return pg.estimate_gradient(lambda x: self.fitness(x), x)\n",
    "    \n",
    "class styblinski_tang:\n",
    "    \n",
    "    def __init__(self, dim = 4):\n",
    "        self.dim = dim\n",
    "        \n",
    "    def fitness(self, x):\n",
    "        return [\n",
    "            np.sum(\n",
    "                np.power(x, 4) - 16 * np.power(x, 2) + 5 * x\n",
    "            ) / 2\n",
    "        ]\n",
    "    \n",
    "    def get_bounds(self):\n",
    "        return ([-5] * self.dim, [5] * self.dim)\n",
    "    \n",
    "    def get_name(self):\n",
    "        return \"Styblinski-Tang Function\"\n",
    "    \n",
    "    def best_known(self):\n",
    "        return np.array([-2.903534] * self.dim)\n",
    "    \n",
    "    def gradient(self, x):\n",
    "        return pg.estimate_gradient(lambda x: self.fitness(x), x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### User Defined Economic Problems\n",
    "Use some functions from the book numerical methods for economics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
