{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define functions for plotting benchmarking results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import inspect\n",
    "import itertools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pygmo as pg\n",
    "import sys\n",
    "\n",
    "from numba import jit\n",
    "\n",
    "%run Test_functions.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Showcase on how to use the Pygmo library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set some parameters first\n",
    "int_dim_rosenbrock = 5\n",
    "int_gen = 1000\n",
    "int_pop_size = 200\n",
    "int_seed = 209311\n",
    "int_verbosity = 1\n",
    "list_algo_name = [\"cmaes\", \"gaco\", \"de\"]\n",
    "\n",
    "# Example problems can be called here. Can define UDPs too.\n",
    "# A problem needs to be constructed with pg.problem\n",
    "prob_rosenbrock = pg.problem(pg.rosenbrock(int_dim_rosenbrock))\n",
    "vec_arg_rosenbrock = pg.rosenbrock(int_dim_rosenbrock).best_known()\n",
    "#float_target_rosenbrock = pg.rosenbro\n",
    "\n",
    "# Most used methods are fitness and get_(f/g/h)evals. Can set a seed.\n",
    "\n",
    "# User defined algorithms are provided by the algorithm type\n",
    "algo_cmaes = pg.algorithm(pg.cmaes(int_gen, seed = int_seed))\n",
    "algo_gaco = pg.algorithm(pg.gaco(int_gen, seed = int_seed))\n",
    "algo_de = pg.algorithm(pg.de(int_gen, seed = int_seed))\n",
    "\n",
    "# To benchmark, we need to set a value > 0 for verbosity to generate a log file\n",
    "algo_cmaes.set_verbosity(int_verbosity)\n",
    "algo_gaco.set_verbosity(int_verbosity)\n",
    "algo_de.set_verbosity(int_verbosity)\n",
    "\n",
    "# The population is a pool of candidate solution to the problem\n",
    "pop_rosenbrock = pg.population(prob_rosenbrock, size = 100, seed = int_seed)\n",
    "\n",
    "# Can get the number of function evaluations by using\n",
    "pop_rosenbrock.problem.get_fevals\n",
    "\n",
    "# Islands are used to allow multithread computation\n",
    "# size gives the number of function evaluations\n",
    "isl_rosenbrock = pg.island(algo = algo_cmaes, prob = prob_rosenbrock, size = 20)\n",
    "\n",
    "# Archipelage is used for parallelization and allow for migration of solutions. \n",
    "# Might be useful as a special case and how this can help.\n",
    "\n",
    "# Solve rosenbrock using three algorithms\n",
    "pop_rosenbrock_cmaes = algo_cmaes.evolve(pop_rosenbrock)\n",
    "pop_rosenbrock_gaco = algo_gaco.evolve(pop_rosenbrock)\n",
    "pop_rosenbrock_de = algo_de.evolve(pop_rosenbrock)\n",
    "\n",
    "# Get the log files as a pandas dataframe\n",
    "log_cmaes_rosenbrock = algo_cmaes.extract(pg.cmaes).get_log()\n",
    "log_gaco_rosenbrock = algo_gaco.extract(pg.gaco).get_log()\n",
    "log_de_rosenbrock = algo_de.extract(pg.de).get_log()\n",
    "\n",
    "# Extract when "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questions\n",
    "\n",
    "- How to take into account, that parameter tuning was used?\n",
    "    - Could start from default settings. (x)\n",
    "    - For every algo get a random grid and check whether the stopping condition is met for such methods.\n",
    "    - Also vary population size. (x)\n",
    "- Since starting points are random should repeat this many times. Can implement the same seed for all algos. (x)\n",
    "- How to find out, when the stopping criterion was reached?\n",
    "    - Lookup log file and find the number of function iterations. (x)\n",
    "- Would also like to show how the population size affects performance. (x)\n",
    "- Maximum accuracy measure $ M $ should be equal to the tolerance considered. This should happen after all optimizers have been tuned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def acc(population, x0, f0, target, f_tol = 1e-06):\n",
    "    \n",
    "    id_best = population.best_idx()\n",
    "    f_best = population.champion_f\n",
    "    x_best = population.champion_x\n",
    "    \n",
    "    # Target is a list supplied by the user\n",
    "    f_prime = target[1]\n",
    "    x_prime = target[0]\n",
    "    \n",
    "    # Calculate accuracy measures\n",
    "    f_acc_n = (f_best - f_prime) / (f0 - f_prime)\n",
    "    x_acc_n = np.linalg.norm(x_best - x_prime) / np.linalg.norm(x0 - x_prime)\n",
    "    f_acc_l = -np.log10(f_acc_n)\n",
    "    x_acc_l = -np.log10(x_acc_n)\n",
    "    #breakpoint()\n",
    "    # Boolean for convergence. Use stopping criteria from pygmo library\n",
    "    converged = (np.abs(f_best - f_prime) < f_tol)\n",
    "    \n",
    "    # Returns a series\n",
    "    list_acc_index = [\"acc_norm_f\", \"acc_norm_x\", \"acc_log_f\", \"acc_log_x\", \"converged\"]\n",
    "    return pd.Series([f_acc_n, x_acc_n, f_acc_l, x_acc_l, converged], \n",
    "                     index = list_acc_index,\n",
    "                     dtype = float\n",
    "                    )\n",
    "\n",
    "def get_results_algo_problem(problem, algorithm_name, target, kwargs_algorithm = None, \n",
    "                             gen = 1000, pop_size = 100, iterations = 100, \n",
    "                             seed = 2093111, verbosity = 1):\n",
    "    \n",
    "    # Get a sequence of seeds for reproducability\n",
    "    array_seeds = np.arange(start = seed, stop = seed + iterations)\n",
    "        \n",
    "    # Empty lists to store logs and evals\n",
    "    list_acc = list()\n",
    "    list_evals = list()\n",
    "    list_logs = list()\n",
    "    \n",
    "    # Now loop over\n",
    "    for iter in range(iterations):\n",
    "        \n",
    "        # Generate a population that with size equal pop_size\n",
    "        population = pg.population(problem, size = pop_size, seed = seed + iter)\n",
    "        \n",
    "        # Multiple starting points. Use best x0 at the starting point.\n",
    "        x0 = population.champion_x\n",
    "        f0 = population.champion_f\n",
    "        \n",
    "        #breakpoint()\n",
    "        if kwargs_algorithm is None:\n",
    "            algorithm = pg.algorithm(getattr(pg, algorithm_name)(gen, seed = seed + iter))\n",
    "        if algorithm_name == \"mbh\":\n",
    "            algorithm = pg.algorithm(getattr(pg, algorithm_name)(seed = seed + iter, **kwargs_algorithm))\n",
    "        else:\n",
    "            algorithm = pg.algorithm(getattr(pg, algorithm_name)(gen, seed = seed + iter, **kwargs_algorithm))\n",
    "        algorithm.set_verbosity(verbosity)\n",
    "        population = algorithm.evolve(population)\n",
    "        log = algorithm.extract(getattr(pg, algorithm_name)).get_log()\n",
    "        #breakpoint()\n",
    "        # Performance profiles need all observations\n",
    "        df_log = pd.DataFrame(log).iloc[:, 0:3]\n",
    "        df_log.columns = [\"gen\", \"f_evals\", \"best\"]\n",
    "        \n",
    "        # Add column for iteration number and algorithm\n",
    "        df_log[\"iteration\"] = iter + 1\n",
    "        df_log[\"algorithm\"] = algorithm_name\n",
    "        \n",
    "        # A column for relative loss log and negative log_10 loss\n",
    "        # Since the log file, doesn't return the best x vector can only compute function loss\n",
    "        df_log[\"acc_norm_f\"] = (df_log[\"best\"] - target[1]) / (f0 - target[1])\n",
    "        df_log[\"acc_log_f\"] = -np.log(df_log[\"acc_norm_f\"])\n",
    "        \n",
    "        # Append results to lists\n",
    "        ser_acc = acc(population, x0, f0, target)\n",
    "        ser_acc[\"iteration\"] = iter + 1\n",
    "        ser_acc[\"algorithm\"] = algorithm_name\n",
    "        list_acc.append(ser_acc)\n",
    "        list_evals.append([\n",
    "            population.problem.get_fevals(),\n",
    "            population.problem.get_gevals(),\n",
    "            population.problem.get_hevals()\n",
    "        ])\n",
    "        list_logs.append(df_log)\n",
    "        \n",
    "    # Put everything together\n",
    "    #breakpoint()\n",
    "    df_acc = pd.DataFrame(list_acc)\n",
    "    df_acc = df_acc.astype({\"converged\": bool})\n",
    "    df_evals = pd.DataFrame(list_evals, columns = [\"f_eval\", \"g_eval\", \"h_eval\"])\n",
    "    df_evals[\"iteration\"] = np.arange(1, iterations + 1)\n",
    "    df_evals[\"algorithm\"] = algorithm_name\n",
    "    df_logs = pd.concat(list_logs)\n",
    "        \n",
    "    return df_acc, df_evals, df_logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "acc_norm_f    9.958784e-13\n",
       "acc_norm_x    1.137660e-05\n",
       "acc_log_f     1.200179e+01\n",
       "acc_log_x     4.943988e+00\n",
       "converged     1.000000e+00\n",
       "dtype: float64"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check accuracy\n",
    "target = [pg.rosenbrock(dim = 5).best_known()]\n",
    "target.append(prob_rosenbrock.fitness(target[0]))\n",
    "x0 = pop_rosenbrock.champion_x\n",
    "f0 = pop_rosenbrock.champion_f\n",
    "acc(pop_rosenbrock_cmaes, x0, f0, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Wilms\\Anaconda3\\lib\\site-packages\\pandas\\core\\series.py:726: RuntimeWarning: divide by zero encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(      acc_norm_f    acc_norm_x  acc_log_f  acc_log_x  converged  iteration  \\\n",
       " 0   2.005449e-26  1.511553e-12  25.697788  11.820577       True        1.0   \n",
       " 1   1.046271e-25  1.525250e-12  24.980356  11.816659       True        2.0   \n",
       " 2   3.600143e-27  1.803605e-12  26.443680  11.743859       True        3.0   \n",
       " 3   4.778339e-03  5.229962e-01   2.320723   0.281501      False        4.0   \n",
       " 4   4.029363e-30  1.034359e-14  29.394764  13.985329       True        5.0   \n",
       " ..           ...           ...        ...        ...        ...        ...   \n",
       " 95  4.785973e-03  8.336453e-01   2.320030   0.079019      False       96.0   \n",
       " 96  1.706487e-27  1.414891e-12  26.767897  11.849277       True       97.0   \n",
       " 97  3.248842e-26  4.355849e-13  25.488271  12.360927       True       98.0   \n",
       " 98  3.322163e-03  2.149745e-01   2.478579   0.667613      False       99.0   \n",
       " 99  6.374234e-28  2.302316e-13  27.195572  12.637835       True      100.0   \n",
       " \n",
       "    algorithm  \n",
       " 0        mbh  \n",
       " 1        mbh  \n",
       " 2        mbh  \n",
       " 3        mbh  \n",
       " 4        mbh  \n",
       " ..       ...  \n",
       " 95       mbh  \n",
       " 96       mbh  \n",
       " 97       mbh  \n",
       " 98       mbh  \n",
       " 99       mbh  \n",
       " \n",
       " [100 rows x 7 columns],\n",
       "     f_eval  g_eval  h_eval  iteration algorithm\n",
       " 0     1386     276       0          1       mbh\n",
       " 1     1797     384       0          2       mbh\n",
       " 2     1010     203       0          3       mbh\n",
       " 3     1272     263       0          4       mbh\n",
       " 4     1757     344       0          5       mbh\n",
       " ..     ...     ...     ...        ...       ...\n",
       " 95     870     164       0         96       mbh\n",
       " 96    1030     223       0         97       mbh\n",
       " 97    1382     272       0         98       mbh\n",
       " 98    1023     216       0         99       mbh\n",
       " 99    1909     395       0        100       mbh\n",
       " \n",
       " [100 rows x 5 columns],\n",
       "      gen       f_evals  best  iteration algorithm  acc_norm_f  acc_log_f\n",
       " 0    160  3.255470e-22     0          1       mbh         0.0        inf\n",
       " 1    286  3.255470e-22     0          1       mbh         0.0        inf\n",
       " 2    409  3.255470e-22     0          1       mbh         0.0        inf\n",
       " 3    531  3.255470e-22     0          1       mbh         0.0        inf\n",
       " 4    659  2.555610e-22     0          1       mbh         0.0        inf\n",
       " ..   ...           ...   ...        ...       ...         ...        ...\n",
       " 9   1303  1.851650e-23     0        100       mbh         0.0        inf\n",
       " 10  1431  1.851650e-23     0        100       mbh         0.0        inf\n",
       " 11  1555  1.851650e-23     0        100       mbh         0.0        inf\n",
       " 12  1680  1.851650e-23     0        100       mbh         0.0        inf\n",
       " 13  1809  1.851650e-23     0        100       mbh         0.0        inf\n",
       " \n",
       " [952 rows x 7 columns])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check whether the function works\n",
    "problem_test = pg.problem(pg.rosenbrock(dim = 5))\n",
    "algorithm_name_test = \"mbh\"\n",
    "kwargs_algorithm = {\"algo\": pg.nlopt(\"lbfgs\")}\n",
    "target = [pg.rosenbrock(dim = 5).best_known()]\n",
    "target.append(prob_rosenbrock.fitness(target[0]))\n",
    "\n",
    "get_results_algo_problem(\n",
    "    problem = problem_test,\n",
    "    algorithm_name = algorithm_name_test,\n",
    "    target = target,\n",
    "    kwargs_algorithm = kwargs_algorithm\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code block runs the same algorithm on a group of problems for differing population sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_results_popsize(problem, algorithm_name, target, kwargs_algorithm = None,\n",
    "                        gen = 1000, list_pop_size = [20, 50, 100, 250], iterations = 100, \n",
    "                        seed = 2093111, verbosity = 1):\n",
    "    \n",
    "    # For different population sizes apply get_results_algo_problem\n",
    "    # Store as a dataframe\n",
    "    # Problem is again defined outside this function\n",
    "    list_acc_popsize = list()\n",
    "    list_evals_popsize = list()\n",
    "    list_logs_popsize = list()\n",
    "    \n",
    "    for pop_size in list_pop_size:\n",
    "        \n",
    "        # Store in differing\n",
    "        df_acc, df_evals, df_logs = get_results_algo_problem(\n",
    "            problem,\n",
    "            algorithm_name,\n",
    "            target,\n",
    "            kwargs_algorithm,\n",
    "            gen,\n",
    "            pop_size,\n",
    "            iterations,\n",
    "            seed,\n",
    "            verbosity\n",
    "        )\n",
    "        \n",
    "        # Set popsize as variable\n",
    "        df_acc[\"pop_size\"] = pop_size\n",
    "        df_evals[\"pop_size\"] = pop_size\n",
    "        df_logs[\"pop_size\"] = pop_size\n",
    "        \n",
    "        list_acc_popsize.append(df_acc)\n",
    "        list_evals_popsize.append(df_evals)\n",
    "        list_logs_popsize.append(df_logs)\n",
    "    \n",
    "    # Put together into one big dataframe\n",
    "    df_acc_popsize = pd.concat(list_acc_popsize)\n",
    "    df_evals_popsize = pd.concat(list_evals_popsize)\n",
    "    df_logs_popsize = pd.concat(list_logs_popsize)\n",
    "    \n",
    "    return df_acc_popsize, df_evals_popsize, df_logs_popsize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(    acc_norm_f  acc_norm_x  acc_log_f  acc_log_x  converged  iteration  \\\n",
       " 0     0.001441    0.547146   2.841466   0.261897      False        1.0   \n",
       " 1     0.000293    0.301309   3.533351   0.520989      False        2.0   \n",
       " 2     0.000478    0.414025   3.320418   0.382973      False        3.0   \n",
       " 3     0.001540    2.089224   2.812557  -0.319985      False        4.0   \n",
       " 4     0.000965    0.070802   3.015428   1.149955      False        5.0   \n",
       " ..         ...         ...        ...        ...        ...        ...   \n",
       " 95    0.017226    0.170188   1.763824   0.769072      False       96.0   \n",
       " 96    0.000137    0.064716   3.863303   1.188987      False       97.0   \n",
       " 97    0.003037    1.036564   2.517561  -0.015596      False       98.0   \n",
       " 98    0.003439    0.345289   2.463544   0.461817      False       99.0   \n",
       " 99    0.003530    0.214277   2.452203   0.669024      False      100.0   \n",
       " \n",
       "    algorithm  pop_size  \n",
       " 0        sea        20  \n",
       " 1        sea        20  \n",
       " 2        sea        20  \n",
       " 3        sea        20  \n",
       " 4        sea        20  \n",
       " ..       ...       ...  \n",
       " 95       sea       250  \n",
       " 96       sea       250  \n",
       " 97       sea       250  \n",
       " 98       sea       250  \n",
       " 99       sea       250  \n",
       " \n",
       " [400 rows x 8 columns],\n",
       "     f_eval  g_eval  h_eval  iteration algorithm  pop_size\n",
       " 0     1022       0       0          1       sea        20\n",
       " 1     1022       0       0          2       sea        20\n",
       " 2     1022       0       0          3       sea        20\n",
       " 3     1022       0       0          4       sea        20\n",
       " 4     1022       0       0          5       sea        20\n",
       " ..     ...     ...     ...        ...       ...       ...\n",
       " 95    1252       0       0         96       sea       250\n",
       " 96    1252       0       0         97       sea       250\n",
       " 97    1252       0       0         98       sea       250\n",
       " 98    1252       0       0         99       sea       250\n",
       " 99    1252       0       0        100       sea       250\n",
       " \n",
       " [400 rows x 6 columns],\n",
       "      gen  f_evals          best  iteration algorithm  acc_norm_f  acc_log_f  \\\n",
       " 0      1        1  15013.186583          1       sea    1.000000  -0.000000   \n",
       " 1      2        2  15013.186583          1       sea    1.000000  -0.000000   \n",
       " 2      3        3  15013.186583          1       sea    1.000000  -0.000000   \n",
       " 3      4        4  13616.159357          1       sea    0.906947   0.097672   \n",
       " 4      5        5   3366.834296          1       sea    0.224258   1.494956   \n",
       " ..   ...      ...           ...        ...       ...         ...        ...   \n",
       " 514  964      964      4.592377        100       sea    0.003530   5.646406   \n",
       " 515  987      987      4.592377        100       sea    0.003530   5.646406   \n",
       " 516  991      991      4.592377        100       sea    0.003530   5.646406   \n",
       " 517  994      994      4.592377        100       sea    0.003530   5.646406   \n",
       " 518  997      997      4.592377        100       sea    0.003530   5.646406   \n",
       " \n",
       "      pop_size  \n",
       " 0          20  \n",
       " 1          20  \n",
       " 2          20  \n",
       " 3          20  \n",
       " 4          20  \n",
       " ..        ...  \n",
       " 514       250  \n",
       " 515       250  \n",
       " 516       250  \n",
       " 517       250  \n",
       " 518       250  \n",
       " \n",
       " [118854 rows x 8 columns])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_results_popsize(prob_rosenbrock, \"sea\", target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get measures for differing problems and algorithms. Use a for loop again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_results_all(\n",
    "    list_problem_names,\n",
    "    list_algorithm_names,\n",
    "    kwargs_problem = None,\n",
    "    kwargs_algorithm = None,\n",
    "    gen = 1000,\n",
    "    list_pop_size = [20, 50, 100, 250],\n",
    "    iterations = 100,\n",
    "    seed = 2093111,\n",
    "    verbosity = 1\n",
    "):\n",
    "    \n",
    "    # Kwargs for problem and algo are a dictionary of dictionaries.\n",
    "    # The Keys are the problem/algortihm name respectively\n",
    "    if kwargs_problem is None:\n",
    "        kwargs_problem = dict()\n",
    "        for problem_name in list_problem_names:\n",
    "            kwargs_problem[problem_name] = None\n",
    "        \n",
    "    if kwargs_algorithm is None:\n",
    "        kwargs_algorithm = dict()\n",
    "        for algorithm_name in list_algorithm_names:\n",
    "            kwargs_algorithm[algorithm_name] = None\n",
    "            \n",
    "    # Check that a kwarg is present for every problem/algorithm\n",
    "    if len(list_problem_names) != len(kwargs_problem):\n",
    "        raise KeyError(\"kwargs_problem has to contain an entry for every problem. If you don't intend \\\n",
    "                       to supply any values set it equal to None\")\n",
    "        \n",
    "    if len(list_algorithm_names) != len(kwargs_algorithm):\n",
    "        raise KeyError(\"kwargs_algorithm has to contain an entry for every algorithm. If you don't intend \\\n",
    "                       to supply any values set it equal to None\")\n",
    "    \n",
    "    # Containers for output\n",
    "    list_acc_all = list()\n",
    "    list_evals_all = list()\n",
    "    list_logs_all = list()\n",
    "    \n",
    "    # Greate a grid of problem and algorithm names over which to loop\n",
    "    for problem_name, algorithm_name in itertools.product(list_problem_names, list_algorithm_names):\n",
    "        \n",
    "        # Some algorithms can't handle \n",
    "        # Define the problem\n",
    "        problem = pg.problem(getattr(pg, problem_name)(**kwargs_problem[problem_name]))\n",
    "        \n",
    "        # Get target for given problem\n",
    "        target = get_target(problem_name, kwargs_problem[problem_name])\n",
    "        # breakpoint()\n",
    "        # Apply the get_results_popsize\n",
    "        df_acc_problem_algorithm, df_evals_problem_algorithm, df_logs_problem_algorithm = \\\n",
    "        get_results_popsize(\n",
    "            problem,\n",
    "            algorithm_name,\n",
    "            target,\n",
    "            kwargs_algorithm[algorithm_name],\n",
    "            gen,\n",
    "            list_pop_size,\n",
    "            iterations,\n",
    "            seed,\n",
    "            verbosity\n",
    "        )\n",
    "        \n",
    "        # Add a column to every dataframe identifying the problem considered\n",
    "        df_acc_problem_algorithm[\"problem\"] = problem_name\n",
    "        df_evals_problem_algorithm[\"problem\"] = problem_name\n",
    "        df_logs_problem_algorithm[\"problem\"] = problem_name\n",
    "        \n",
    "        # Put into list containers\n",
    "        list_acc_all.append(df_acc_problem_algorithm)\n",
    "        list_evals_all.append(df_evals_problem_algorithm)\n",
    "        list_logs_all.append(df_logs_problem_algorithm)\n",
    "        \n",
    "    # Put into dataframe format\n",
    "    df_acc_all = pd.concat(list_acc_all)\n",
    "    df_evals_all = pd.concat(list_evals_all)\n",
    "    df_logs_all = pd.concat(list_logs_all)\n",
    "    \n",
    "    return df_acc_all, df_evals_all, df_logs_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "_mbh_init() got multiple values for argument 'algo'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-33-1b30b8a08326>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0mlist_algorithm_names\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0mkwargs_problem\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m     \u001b[0mkwargs_algorithm\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m )\n",
      "\u001b[1;32m<ipython-input-29-fc87e37eb7fa>\u001b[0m in \u001b[0;36mget_results_all\u001b[1;34m(list_problem_names, list_algorithm_names, kwargs_problem, kwargs_algorithm, gen, list_pop_size, iterations, seed, verbosity)\u001b[0m\n\u001b[0;32m     58\u001b[0m             \u001b[0miterations\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m             \u001b[0mseed\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 60\u001b[1;33m             \u001b[0mverbosity\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     61\u001b[0m         )\n\u001b[0;32m     62\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-12-0e46ebf22286>\u001b[0m in \u001b[0;36mget_results_popsize\u001b[1;34m(problem, algorithm_name, target, kwargs_algorithm, gen, list_pop_size, iterations, seed, verbosity)\u001b[0m\n\u001b[0;32m     22\u001b[0m             \u001b[0miterations\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m             \u001b[0mseed\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m             \u001b[0mverbosity\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m         )\n\u001b[0;32m     26\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-25-4931bb49f856>\u001b[0m in \u001b[0;36mget_results_algo_problem\u001b[1;34m(problem, algorithm_name, target, kwargs_algorithm, gen, pop_size, iterations, seed, verbosity)\u001b[0m\n\u001b[0;32m     50\u001b[0m             \u001b[0malgorithm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0malgorithm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malgorithm_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mseed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mseed\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0miter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 52\u001b[1;33m             \u001b[0malgorithm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0malgorithm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malgorithm_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mseed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mseed\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0miter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs_algorithm\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     53\u001b[0m         \u001b[0malgorithm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_verbosity\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mverbosity\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m         \u001b[0mpopulation\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0malgorithm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevolve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpopulation\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: _mbh_init() got multiple values for argument 'algo'"
     ]
    }
   ],
   "source": [
    "list_problem_names = [\"rosenbrock\", \"rastrigin\", \"schwefel\", \"ackley\"]\n",
    "list_algorithm_names = [\"de\", \"cmaes\", \"mbh\"]\n",
    "kwargs_problem = {\"rosenbrock\": {\"dim\": 5}, \"rastrigin\": {\"dim\": 3}, \"schwefel\": {\"dim\": 2}, \"ackley\": {\"dim\": 10}}\n",
    "kwargs_algorithm = {\"de\": None, \"cmaes\": None, \"mbh\": {\"algo\": pg.nlopt(\"lbfgs\")}}\n",
    "\n",
    "get_results_all(\n",
    "    list_problem_names,\n",
    "    list_algorithm_names,\n",
    "    kwargs_problem,\n",
    "    kwargs_algorithm\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup\n",
    "\n",
    "Need to get some solved optimization algorithms first. Test with the Ackley function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_problem_names = [\"rosenbrock\", \"rastrigin\",\"schwefel\", \"ackley\", \"griewank\", \n",
    "                      \"lennard_jones\", \"luksan_vlcek1\", \"cec2014\",\n",
    "                     \"cec2013\", \"cec2006\"]\n",
    "list_algorithm_names = [\"bee_colony\", \"de\", \"sea\", \"sga\", \"sade\", \"cmaes\", \n",
    "                        \"pso\", \"pso_gen\", \"mbh\"]\n",
    "kwargs_problem = {\"rosenbrock\": {\"dim\": 5}, \"rastrigin\": {\"dim\": 10}, \"schwefel\": {\"dim\": 2},\n",
    "                 \"ackley\": {\"dim\": 4}, \"griewank\": {\"dim\": 6}, \"lennard_jones\": {\"atoms\": 30},\n",
    "                 \"luksan_vlcek1\": {\"dim\": 7}, \"cec2014\": {\"prob_id\": 1, \"dim\": 8},\n",
    "                 \"cec2013\": {\"prob_id\": 2, \"dim\": 3}, \"cec2006\": {\"prob_id\": 3}}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trajectory Plot\n",
    "\n",
    "A trajectory plot shows how the algorithm moved from iteration to iteration. Want to have one plot for multiple algorithms. EA need a single plot with multiple points. Since all algos start from multiple points it could be wise to have an animated plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convergence Plot\n",
    "\n",
    "Plots the best function value against the number of function evaluations. An average runtime plot could be useful. For example how it changes with "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance profiles\n",
    "For a given set of problems $ \\mathcal{P} $, solvers $ \\mathcal{S} $ and a convergence test $ \\mathcal{T} $. They are a performance measre $ t_{p, s} > 0 $, where $ p,\\, s $ are indices for a given problem and solver $ (p, s) \\in \\mathcal{P} \\times \\mathcal{S} $. Now the value $ r_{p, s} $ is defined as:\n",
    "\n",
    "$$ r_{p, s} = \\begin{cases} \n",
    "\\frac{t_{p, s}}{\\min\\{t_{p, s}: \\, s \\in \\mathcal{S} \\}} \\quad \\text{if convergence is passed} \\\\\n",
    "\\infty \\quad \\text{if convergence fails}\n",
    "\\end{cases} $$\n",
    "\n",
    "The best performing optimizer will have $ r_{p, s} = 1 $. For a specific problem $ p $ and cutoff $ \\tau > 1 $, the performance profile for solver $ s $ is defined as follows:\n",
    "\n",
    "$$ \\rho_s(\\tau) = \\frac{1}{|\\mathcal{P}|} \\text{size} \\{p \\in \\mathcal{P}: \\, r_{p, s} \\leq \\tau \\} $$\n",
    "\n",
    "where $ |\\mathcal{P} | $ is the cardinality of the set $ \\mathcal{P} $. $ \\rho_s(1) $ represents the fraction that solver $ s $ is the best performing solver. Want to identify solvers with high values. Remember that performance profiles depend of the solvers considered. For comparing only two optimizers a new profile should be drawn.\n",
    "\n",
    "Important is what measure we consider for performance. Possible are function value or distance to optimal solution. For measuring performance by function value\n",
    "\n",
    "$$ m_{p, s} = \\frac{\\hat{f}_{p, s}(k) - f^*}{f_w - f^*} $$\n",
    "\n",
    "where $ k $ is the value of function evaluations and $ f_w $ is the worst value after $ k $ evaluations.\n",
    "\n",
    "Performance profiles can allow to assess both speed and success rate. However, caution is advised as it is not ceretain that the best solution found is the best."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy Profiles\n",
    "Visualize an entire benchmarking test set. Only applicable for fixed-cost problems. For every $ s \\in \\mathcal{S} $ and $ p \\in \\mathcal{P} $, we calculate an accuracy measure is calculated, where $ M $ is a maximum improvement value. \n",
    "\n",
    "$$ \\gamma_{p, s} = \\begin{cases}\n",
    "-f_{acc}^{p, s}, \\quad \\text{if } -f_{acc}^{p, s} \\leq M \\\\\n",
    "M, \\quad -f_{acc}^{p, s} > M \\text{ or } f_{acc}^{p, s} \\text{ is undefined}\n",
    "\\end{cases} $$\n",
    "\n",
    "where $ f_{acc}^{p, s} = \\log_{10}(f(\\bar{x}_{p, s} - f(x_p^*)) - \\log_{10}(f(x_p^0) - f(x_p^*)) $, $ x_{p, s} $ is the candidate solution, obtained by solver $ s $ for problem $ p $, $ x_p^* $ is the optimal point for problem $ p $, and $ x_p^0 $ is the initial point for problem $ p $. To measure the performance we calculate \n",
    "\n",
    "$$ R_s (\\tau) = \\frac{1}{|\\mathcal{P}|} \\text{size} \\{ \\gamma_{p, s} | \\gamma_{p, s} \\geq \\tau, \\, p \\in \\mathcal{P} \\} $$\n",
    "\n",
    "it shows the proportion of problems for which the solver $ s $ achieves an accuracy of at least $ \\tau $. Only suitable for fixed cost data-sets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Profiles\n",
    "Proposed for derivative-free optimization algorithms. They show, which percentage of problems for a given value $ \\tau $ can be solved within the budget of $ k $ function evaluations. Since it is assumed, that the number of functions evluations grows with the dimension of the problem $ n_p $, it is defined as\n",
    "\n",
    "$$ d_s (k) = \\frac{1}{\\mathcal{P}} \\text{size} \\{p \\in \\mathcal{P}: \\, \\frac{t_{p, s}}{n_p + 1} \\leq k \\}$$\n",
    "\n",
    "\n",
    "here, $ t_{p, s} $ is the number of function evaluations required to satisfy the convergence test, $ d_s (k) $ is the fraction of problems $ p $ solved by $ s $ within $ k $ evaluations. Data profiles are independent of other solvers. To compare gradient-free and gradient-based methods I will also implement a data profiles that accounts for number of gradient and hessian evaluations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
